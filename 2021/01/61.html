


<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>  使用代理池处理反爬抓取微信文章 |    云淡风轻</title>
  <meta name="description" content="The future is you, the future can be expected.">
  <!-- 标签页图标 -->
  

  <!-- 图标库 -->
  <link href="https://cdn.jsdelivr.net/npm/remixicon@2.2.0/fonts/remixicon.css" rel="stylesheet">
  <!-- 动画库 -->
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/fushaolei/cdn-white@1.0/css/animate.css"/>
  
  <!-- css文件 -->
  
<link rel="stylesheet" href="/css/white.css">

  <!-- 代码高亮 -->
  
    
      
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.1.1/styles/github.css">

    
  
  <script data-ad-client="ca-pub-8199652999435074" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<meta name="generator" content="Hexo 5.3.0"></head>


<body>

<div class="menu-outer">
    <div class="menu-inner">
      <div class="menu-site-name  animate__animated  animate__fadeInUp">
        <a href="/">
          云淡风轻
        </a>
        
      </div>
      <div class="menu-group">
        <ul class="menu-ul">
        
          <a href="/" class="nav-link">
            <li class="menu-li  animate__animated  animate__fadeInUp">
              HOME
            </li>
          </a>
        
          <a href="/archives" class="nav-link">
            <li class="menu-li  animate__animated  animate__fadeInUp">
              BLOG
            </li>
          </a>
        
        
        
        <a href="/search">
          <li class="menu-li  animate__animated  animate__fadeInUp">
            <i class="ri-search-line"></i>
          </li>
        </a>
        
          <li class="menu-li animate__animated  animate__fadeInUp" id="mobile-menu">
            <i class="ri-menu-line"></i>
          </li>
        
        </ul>

      </div>

    </div>
</div>
<div id="mobile-main" class="animate__animated  animate__fadeIn">
  <div class="mobile-menu-inner">
    <div class="mobile-menu-site-name animate__animated  animate__fadeInUp">
      <a href="/">
        云淡风轻
      </a>
    </div>
    <div class="mobile-menu-group" id="mobile-close">
      <i class="ri-close-line"></i>
    </div>

  </div>

  <div class="mobile-menu-div">
  
    <a href="/" class="mobile-nav-link">
      <div class="mobile-menu-child animate__animated  animate__fadeInUp">
        <span>HOME</span>
      </div>
    </a>
  
    <a href="/archives" class="mobile-nav-link">
      <div class="mobile-menu-child animate__animated  animate__fadeInUp">
        <span>BLOG</span>
      </div>
    </a>
  
  
    <a href="/search">  
      <div class="mobile-menu-child  animate__animated  animate__fadeInUp">
        <i class="ri-search-line"></i>
      </div>
    </a>
    
  </div>


</div>

<div class="body-outer">
  <div class="body-inner">
    
<article class="post-inner">
  <div class="post-content-outer">
    <div class="post-intro">
      <div class="post-title animate__animated  animate__fadeInUp">使用代理池处理反爬抓取微信文章</div>
      <div class="meta-intro animate__animated  animate__fadeInUp">1月 27 2021</div>
      
    </div>
    <div class="post-content-inner">
      <div class="post-content-inner-space">

      </div>
      <div class="post-content-main animate__animated  animate__fadeInUp">
        <!-- top型目录 -->
        
        <blockquote>
<p>搜狗（<a target="_blank" rel="noopener" href="http://weixin.sogou.com/%EF%BC%89%E5%B7%B2%E7%BB%8F%E4%B8%BA%E6%88%91%E4%BB%AC%E5%81%9A%E4%BA%86%E4%B8%80%E5%B1%82%E5%BE%AE%E4%BF%A1%E6%96%87%E7%AB%A0%E7%9A%84%E7%88%AC%E5%8F%96%EF%BC%8C%E9%80%9A%E8%BF%87%E5%AE%83%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E8%8E%B7%E5%8F%96%E4%B8%80%E4%BA%9B%E5%BE%AE%E4%BF%A1%E6%96%87%E7%AB%A0%E7%9A%84%E5%88%97%E8%A1%A8%E4%BB%A5%E5%8F%8A%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BF%A1%E6%81%AF%EF%BC%8C">http://weixin.sogou.com/）已经为我们做了一层微信文章的爬取，通过它我们可以获取一些微信文章的列表以及微信公众号的一些信息，</a><br>但是它有很多反爬虫的措施，可以检测到你的IP异常，然后把你封掉。<br>本文采用代理的方法处理反爬来抓取微信文章。</p>
</blockquote>
<a id="more"></a>
<h1 id="用到的"><a href="#用到的" class="headerlink" title="用到的"></a>用到的</h1><ul>
<li>urllib</li>
<li>lxml</li>
<li>pyquery</li>
<li>requests</li>
<li>re</li>
<li>pymongo</li>
<li>sys</li>
</ul>
<h1 id="代理池"><a href="#代理池" class="headerlink" title="代理池"></a>代理池</h1><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/Python3WebSpider/ProxyPool">https://github.com/Python3WebSpider/ProxyPool</a></li>
</ul>
<h1 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h1><p>
        <span class="lazyload-img-span">
        <img   
           data-src="https://p.pstatp.com/origin/137fe00030644a02199da" >
        </sapn>
      </p>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><pre><code># -*- coding: utf-8 -*-
&quot;&quot;&quot;
@Time ： 2021/1/27 12:29
@Auth ： Ne-21
@File ：weixin_spider.py
@IDE ：PyCharm
@Motto：Another me.

&quot;&quot;&quot;
from urllib.parse import urlencode
from lxml.etree import XMLSyntaxError
from pyquery import PyQuery as pq
import requests
import re
import pymongo
import sys

sys.setrecursionlimit(3000)  # 将默认的递归深度修改为3000

base_url = &#39;https://weixin.sogou.com/weixin?&#39;
headers = &#123;
    &#39;Referer&#39;: &#39;https://weixin.sogou.com/weixin?query=%E9%A3%8E%E6%99%AF&amp;type=2&amp;page=1&amp;ie=utf8&#39;,
    &#39;Sec-Fetch-Dest&#39;: &#39;document&#39;,
    &#39;Sec-Fetch-Mode&#39;: &#39;navigate&#39;,
    &#39;Sec-Fetch-Site&#39;: &#39;same-origin&#39;,
    &#39;Sec-Fetch-User&#39;: &#39;?1&#39;,
    &#39;Upgrade-Insecure-Requests&#39;: &#39;1&#39;,
    &#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 &#39;
                  &#39;Safari/537.36&#39;,
    &#39;Host&#39;: &#39;weixin.sogou.com&#39;,
    &#39;Cookie&#39;: &#39;&#39;
    &#125;
keyword = &#39;云计算&#39;

# 获取、设置全局代理
proxy_pool_url = &#39;http://127.0.0.1:5555/random&#39;
proxy = None

# 最大请求次数
max_count = 5

# MongoDB
MONGO_URL = &#39;localhost&#39;
MONGO_DB = &#39;weixin&#39;
MONGO_TABLE = &#39;articles&#39;

client = pymongo.MongoClient(MONGO_URL)
db = client[MONGO_DB]

# 获取代理信息
def get_proxy():
    try:
        response = requests.get(proxy_pool_url)
        if response.status_code == 200:
            return response.text
        return None
    except ConnectionError:
        return None


# 搜索
def get_index(keyword, page):
    data = &#123;
        &#39;query&#39;: keyword,
        &#39;page&#39;: page,
        &#39;type&#39;: &#39;2&#39;
    &#125;
    queries = urlencode(data)
    url = base_url + queries
    html = get_html(url)
    return html


# 获取搜索页面信息
def get_html(url, count=1):
    print(&#39;请求目标网址&#39;, url)
    print(&#39;当前请求次数&#39;, count)
    global proxy
    # 判断请求次数
    if count == max_count:
        print(&#39;请求次数过多&#39;)
        return None
    try:
        # 是否有代理
        if proxy:
            proxies = &#123;
                &#39;http&#39;: &#39;http://&#39; + proxy
            &#125;
            response = requests.get(url, headers=headers, allow_redirects=False, proxies=proxies)
        else:
            # allow_redirects=False 不处理自动跳转
            response = requests.get(url, headers=headers, allow_redirects=False)
        if response.status_code == 200:
            return response.text
        if response.status_code == 302:
            # need proxy
            print(&#39;302&#39;)
            proxy = get_proxy()
            if proxy:
                print(&#39;Using Proxy&#39;, proxy)
                # count += 1
                return get_html(url)
            else:
                print(&#39;Get Proxy Failed&#39;)
                return None
    except ConnectionError as e:
        print(&#39;Error&#39;, e.args)
        proxy = get_proxy()
        count += 1
        return get_html(url, count)


# 解析搜索页面
def parse_index(html):
    doc = pq(html)
    items = doc(&#39;.news-box .news-list li .txt-box h3 a&#39;).items()
    for item in items:
        yield str(&#39;https://weixin.sogou.com&#39;) + item.attr(&#39;href&#39;)


# 获取真实的文章地址
def get_detail_true_url(url):
    global proxy
    try:
        if proxy:
            proxies = &#123;
                &#39;http&#39;: &#39;http://&#39; + str(proxy)
            &#125;
            response = requests.get(url, headers=headers, allow_redirects=False, proxies=proxies)
        else:
            # allow_redirects=False 不处理自动跳转
            response = requests.get(url, headers=headers, allow_redirects=False)
        if response.status_code == 200:
            response = response.text
            url_param = re.compile(&quot;url \+= &#39;(.*?)&#39;;&quot;, re.S).findall(response)
            true_url = &#39;&#39;
            for i in url_param:
                true_url += i
            true_url.replace(&#39;@&#39;, &#39;&#39;)
            return true_url
    except:
        return get_detail_true_url(url)


# 获取文章详情
def get_detail(true_url):
    try:
        response = requests.get(true_url)
        if response.status_code == 200:
            response = response.text
            return response
        return None
    except ConnectionError:
        return None


# 解析文章
def parse_detail(html):
    try:
        doc = pq(html)
        title = doc(&#39;.rich_media_title&#39;).text()
        content = doc(&#39;.rich_media_content&#39;).text()
        date = doc(&#39;#publish_time&#39;).text()
        nickname = doc(&#39;#js_name&#39;).text()
        wechat = doc(&#39;#js_profile_qrcode &gt; div &gt; p:nth-child(3) &gt; span&#39;).text()
        return &#123;
            &#39;title&#39;: title,
            &#39;content&#39;: content,
            &#39;date&#39;: date,
            &#39;nickname&#39;: nickname,
            &#39;wechat&#39;: wechat
        &#125;
    except XMLSyntaxError:
        return None



def save_to_mongo(data):
    # 如果有一样的，更新，没有，插入
    if db[MONGO_TABLE].update(&#123;&#39;title&#39;: data[&#39;title&#39;]&#125;, &#123;&#39;$set&#39;: data&#125;, True):
        print(&#39;存储到数据库成功&#39;, data[&#39;title&#39;])
    else:
        print(&#39;存储失败&#39;, data[&#39;title&#39;])

def main():
    for page in range(1, 100):
        html = get_index(keyword, page)
        if html:
            article_urls = parse_index(html)
            for article_url in article_urls:
                article_html = get_detail_true_url(article_url)
                article_true_html = get_detail(article_html)
                if article_true_html:
                    article_data = parse_detail(article_true_html)
                    print(article_data)
                    if article_data:
                        save_to_mongo(article_data)


if __name__ == &#39;__main__&#39;:
    main()
</code></pre>

        <!-- 分类文章 -->
        
      </div>
      <div class="post-content-inner-space">
        
          <div class="space-toc-main animate__animated  animate__fadeInUp">
            
           </div>
        
      </div>
   </div>
    <!-- 评论 -->
    
    <div class="bottom-comments-outer">
      <div class="bottom-comments-inner">
        <!-- valine -->
        
          <section id="comments" class="comments" style="margin-top: 150px;">
            <style>
              .comments{background:#fff}
              @media screen and (max-width:900px){.comments{margin:auto;padding:10px;background:#fff}}
            </style>
            <div id="vcomment" class="comment"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script src="https://cdnjs.loli.net/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
<script>
    var notify = 'true' == true ? true : false;
    var verify = 'true' == true ? true : false;
    new Valine({
        av: AV,
        el: '#vcomment',
        notify: notify,
        app_id: "oLziw6ntaHtCC9A0HLYYu5OE-gzGzoHsz",
        app_key: "KjHsec1b3kguAMPQ7io7JlFs",
        placeholder: "留下你来过的痕迹~",
        avatar:"robohash",
    });
</script>

          </section>
        
        <!-- Gitalk -->
        
        <!-- livere -->
        
        </div>
      </div>
    
  </div>
</article>
  </div>
</div>



<!-- 如果是home模式的话，不在首页就显示footer，如果不是home模式的话 所有都显示footer -->

  <div class="footer-outer animate__animated  animate__fadeInUp">
    <div class="footer-inner">
    <div class="footer-text">
    <p>© 2021 云淡风轻|<a target="_blank" rel="noopener" href="https://www.beian.miit.gov.cn/">冀ICP备19031443号</a><br><a href="https://www.upyun.com/?utm_source=lianmeng&utm_medium=referral" target="_blank"><img src="https://imgs.521daigua.cn/%E6%A0%B7%E5%BC%8F%E5%9B%BE.7cf927c.png" width="300px" height="20px"></a><br><script data-ad-client="ca-pub-8199652999435074" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script></p>

    </div>
    <div class="footer-contact">
    <ul class="footer-ul">
        
        <li class="footer-li">
            <a href="https://github.com/ne-21" target="_blank">
                <i class="ri-github-line"></i>
            </a>
        </li>
        
        <li class="footer-li">
            <a href="mailto:nawlgzs@gmail.com" target="_blank">
                <i class="ri-mail-line"></i>
            </a>
        </li>
        
    </ul>
    </div>
    </div>
	<script>
	var _hmt = _hmt || [];
	(function() {
	var hm = document.createElement("script");
	hm.src = "https://hm.baidu.com/hm.js?46c8202ccbfe91fef8f7d5fddc0ce94a";
	var s = document.getElementsByTagName("script")[0]; 
	s.parentNode.insertBefore(hm, s);
	})();
	</script>
</div>






<script src="/js/white.js"></script>



    
      
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.1/build/highlight.min.js"></script>

      <script>hljs.initHighlightingOnLoad();</script>
    

</body>
</html>
